In the src/ directory, run ./compile.sh to compile the data processing program.
Then, run the resulting executable:
./dump_data input.s16 exc.s8 features.f32 pred.s16 pcm.s16

where the first file contains 16 kHz 16-bit raw PCM audio (no header)
and the other files are output files. The input file I'm using currently
is 6 hours long, but you may be able to get away with less (and you can
always use Â±5% or 10% resampling to augment your data).

Now that you have your files, you can do the training with:
./train_wavenet_audio.py exc.s8 features.f32 pred.s16 pcm.s16
and it will generate a wavenet*.h5 file for each iteration.

You can do the synthesis with:
./test_wavenet_audio.py features.f32 > pcm.txt

If you're lucky, you may be able to get the current model at:
https://jmvalin.ca/misc_stuff/lpcnet_models/
